{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description\n",
    "\n",
    "In this notebook we will build an RNN which will learn from a list of patent abstracts. We will utilise this RNN to predict the next word in a sequence of words, and also to create its own patent abstracts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Approach \n",
    "\n",
    "This project consists of the following steps:\n",
    "\n",
    "1. Reading in the data: thousands of neural network patents\n",
    "2. Converting patents to integer sequences: `tokenization`\n",
    "3. Creating training dataset using the next word following in a sequence as label\n",
    "4. Building a recurrent neural network using word embeddings and LSTM cells\n",
    "5. Training the network to predict the next word from the sequence\n",
    "6. Generating new abstracts by feeding a seed sequence to a network\n",
    "7. Loading pre-trained embeddings\n",
    "8. Repeating steps 3 - 7 using the pre-trained embeddings\n",
    "9. Trying out different model architectures to see if the performance improves\n",
    "10. For fun, creating a simple game where we must guess if the output is human or computer generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loding the data\n",
    "\n",
    "First we load the date along with some necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import gc\n",
    "import os\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category = RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total of 3522 patent abstracts.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" A \"\"Barometer\"\" Neuron enhances stability in...</td>\n",
       "      <td>1996-07-09</td>\n",
       "      <td>5535303</td>\n",
       "      <td>\"\"\"Barometer\"\" neuron for a neural network\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\" This invention is a novel high-speed neural ...</td>\n",
       "      <td>1993-10-19</td>\n",
       "      <td>5255349</td>\n",
       "      <td>\"Electronic neural network for solving \"\"trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An optical information processor for use as a ...</td>\n",
       "      <td>1995-01-17</td>\n",
       "      <td>5383042</td>\n",
       "      <td>3 layer liquid crystal neural network with out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A method and system for intelligent control of...</td>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>6169981</td>\n",
       "      <td>3-brain architecture for an intelligent decisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A method and system for intelligent control of...</td>\n",
       "      <td>2003-06-17</td>\n",
       "      <td>6581048</td>\n",
       "      <td>3-brain architecture for an intelligent decisi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     patent_abstract patent_date  \\\n",
       "0  \" A \"\"Barometer\"\" Neuron enhances stability in...  1996-07-09   \n",
       "1  \" This invention is a novel high-speed neural ...  1993-10-19   \n",
       "2  An optical information processor for use as a ...  1995-01-17   \n",
       "3  A method and system for intelligent control of...  2001-01-02   \n",
       "4  A method and system for intelligent control of...  2003-06-17   \n",
       "\n",
       "  patent_number                                       patent_title  \n",
       "0       5535303        \"\"\"Barometer\"\" neuron for a neural network\"  \n",
       "1       5255349  \"Electronic neural network for solving \"\"trave...  \n",
       "2       5383042  3 layer liquid crystal neural network with out...  \n",
       "3       6169981  3-brain architecture for an intelligent decisi...  \n",
       "4       6581048  3-brain architecture for an intelligent decisi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../neural_network_patent_query.csv',\n",
    "                  parse_dates = ['patent_date'])\n",
    "\n",
    "abstracts = list(data['patent_abstract'])\n",
    "\n",
    "print(f'There are total of {len(abstracts)} patent abstracts.')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Formatting\n",
    "\n",
    "Let's print out one of the abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The present invention provides an apparatus and a method for classifying and recognizing image patterns using a second-order neural network, thereby achieving high-rate parallel processing while lowering the complexity. The second-order neural network, which is made of adders and multipliers, corrects positional translations generated in a complex-log mapping unit to output the same result for the same object irrespective of the scale and/or rotation of the object. The present invention enables high-rate image pattern classification and recognition based on parallel processing, which is the advantage obtained in neural network models, because consistent neural networks and consistent network structure computation models are applied to all steps from the image input step to the pattern classifying and recognizing step.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on we will use the Tokenizer to convert words of each abstract to integers, so we can train the RNN. However, there's a problem with punctuation - the Tokenizer will recognize `network` and `network,` as two different words. That's why we need to format abstracts by separating punctuation marks from the words. We'll also perform some additional formatting, such as removing numbers encircled in bracets `i.e. (3)` which appear quite often in patents' abstracts to reference to a figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_abstract(abstract):\n",
    "    \n",
    "    #separating a word from the punctuation sign\n",
    "    f_abstract = re.sub(r'(?<=[^\\s0-9])(?=[.,;?])', r' ', abstract)\n",
    "    \n",
    "    #removing reference numbers\n",
    "    f_abstract = re.sub(r'\\(\\d+\\)', r'', f_abstract)\n",
    "    \n",
    "    #removing double spaces\n",
    "    f_abstract = re.sub(r'\\s\\s', ' ', f_abstract)\n",
    "    \n",
    "    return f_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(f_abstract):\n",
    "    \n",
    "    \"\"\"Removes spaces around punctuation\"\"\"\n",
    "    abstract = re.sub(r'\\s+([.,?!;])', r'\\1', f_abstract)\n",
    "    \n",
    "    \n",
    "    return f_abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how our formated patent abstract looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The present invention provides an apparatus and a method for classifying and recognizing image patterns using a second-order neural network , thereby achieving high-rate parallel processing while lowering the complexity . The second-order neural network , which is made of adders and multipliers , corrects positional translations generated in a complex-log mapping unit to output the same result for the same object irrespective of the scale and/or rotation of the object . The present invention enables high-rate image pattern classification and recognition based on parallel processing , which is the advantage obtained in neural network models , because consistent neural networks and consistent network structure computation models are applied to all steps from the image input step to the pattern classifying and recognizing step .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_abstract(abstracts[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total of 3522 (formatted) patent abstracts.\n"
     ]
    }
   ],
   "source": [
    "#formatting all the abstracts\n",
    "formatted_abstracts = [format_abstract(abst) for abst in abstracts]\n",
    "\n",
    "print(f'There are total of {len(formatted_abstracts)} (formatted) patent abstracts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Texts to Sequences\n",
    "\n",
    "As said before, using the Tokenizer we need to convert our texts into sequences of integers to train the RNN. In addition, we need to create feature vectors and labels from those sequences. From each patent abstract we'll create a set of feature vectors and corresponding labels. Each feature vector will represent first $i + 50,\\ (i = 0,1,...)$ words taken from the texts, while the following word will be used as a label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following function will convert texts to integer sequences\n",
    "#and generate feature vectors and corresponding labels\n",
    "def make_sequences(texts, filters,\n",
    "                   training_length = 50, lower = True):\n",
    "    \n",
    "    \n",
    "    \"\"\"Converts texts into integer sequences\"\"\"\n",
    "    \n",
    "    #creating and fitting the Tokenizer\n",
    "    tokenizer = Tokenizer(lower = lower, filters = filters)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    \n",
    "    \n",
    "    #creating dictionaries and 'reverse dictionaries'\n",
    "    #for all the words appearing in patent abstracts\n",
    "    word_idx = tokenizer.word_index\n",
    "    idx_word = tokenizer.index_word\n",
    "    #we add +1 because of the index\n",
    "    num_of_words = len(word_idx) + 1\n",
    "    word_count = tokenizer.word_counts\n",
    "    \n",
    "    print(f'There are {num_of_words - 1} unique words in the dictionary.')\n",
    "    \n",
    "    \n",
    "    #converting texts to integer sequences\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    #we'll select only those abstracts that have a bit more words \n",
    "    #than the feature vector length\n",
    "    seq_lengts = [len(seq) for seq in sequences]\n",
    "    \n",
    "    long_text_idx = [i for i, seq_l in enumerate(seq_lengts)\n",
    "                    if seq_l > (training_length + 20)]\n",
    "    \n",
    "    new_texts = []\n",
    "    new_sequences = []\n",
    "    \n",
    "    for i in long_text_idx:\n",
    "        new_texts.append(texts[i])\n",
    "        new_sequences.append(sequences[i])\n",
    "        \n",
    "    #from every abstract we extract sets of feature vectors and \n",
    "    #corresponding labels\n",
    "    \n",
    "    training_seq = []\n",
    "    labels = []\n",
    "    \n",
    "    for seq in new_sequences:\n",
    "        for i in range(training_length, len(seq)):\n",
    "            extract = seq[i - training_length : i+1]\n",
    "            training_seq.append(extract[:-1])\n",
    "            labels.append(extract[-1])\n",
    "            \n",
    "    print(f'There are {len(training_seq)} training sequences.')\n",
    "    \n",
    "    return word_idx, idx_word, num_of_words, word_count, new_texts, new_sequences, training_seq, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how our function generates data. We'll remove a fair amount of the punctuation and lowercase all letters but leave in periods and commas. Our model will not learn how to capitalize words, but it may learn how to end a sentence and insert commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13676 unique words in the dictionary.\n",
      "There are 320881 training sequences.\n"
     ]
    }
   ],
   "source": [
    "filters = '!\"#$%&()*+/:<=>@[\\\\]^_`{|}~\\t\\n'\n",
    "\n",
    "word_idx, idx_word, num_of_words, word_count, f_abstracts, sequences, features, labels = make_sequences(\n",
    "    formatted_abstracts, filters) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every training sequence/label pair, we'll define a function which will give us the training sequence text and the word (label) that follows it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_label(index):\n",
    "    \n",
    "    '''Outputs the text of a training sequence and the \n",
    "    corresponding label for a given index of a train sequence'''\n",
    "    \n",
    "    #training set text\n",
    "    feat_text = ' '.join(idx_word[i] for i in features[index])\n",
    "    \n",
    "    #label\n",
    "    label = idx_word[labels[index]]\n",
    "    \n",
    "    print(f'Feature text: {feat_text}\\n')\n",
    "    print(f'Label: {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature text: it comprises a novel hybrid architecture employing a binary synaptic array whose embodiment incorporates the fixed rules of the problem , such as the number of cities to be visited . the array is prompted by analog voltages representing variables such as distances . the processor incorporates two interconnected feedback\n",
      "\n",
      "Label: networks\n"
     ]
    }
   ],
   "source": [
    "the_label(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to check what are the most frequent words appearing in our data. Sometimes these words can create bias and weaken the training of our RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 36597),\n",
       " ('a', 24883),\n",
       " ('of', 20193),\n",
       " ('.', 16604),\n",
       " (',', 15417),\n",
       " ('and', 12947),\n",
       " ('to', 12073),\n",
       " ('network', 7733),\n",
       " ('neural', 7381),\n",
       " ('is', 7213),\n",
       " ('in', 6992),\n",
       " ('for', 6907),\n",
       " ('an', 6061),\n",
       " ('data', 4010),\n",
       " ('by', 3607)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_count.items(), key = lambda x: x[1], reverse = True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not remove any of the most common words since they make sense in the context of the patents we are using and the general English language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validation Sets\n",
    "\n",
    "Now it's time to create train and validation sets. We use 70% of our data for the training set. In addition, we one-hot encode the labels since we are going to use categorical-crossentropy as a loss function.\n",
    "\n",
    "We shuffle the features since they are made in a sequential order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def make_train_val(features, labels, num_of_words,\n",
    "                  training_fraction = 0.7):\n",
    "    \n",
    "    '''Splits the data into a training and validation set.'''\n",
    "    \n",
    "    \n",
    "    #shuffling the data\n",
    "    features, labels = shuffle(features, labels, random_state = 50)\n",
    "    \n",
    "    #splitting the data\n",
    "    train_end = int(training_fraction*len(labels))\n",
    "    \n",
    "    train_features = features[:train_end]\n",
    "    val_features = features[train_end:]\n",
    "    \n",
    "    train_labels = labels[:train_end]\n",
    "    val_labels = labels[train_end:]\n",
    "    \n",
    "    #converting the data into a numpy arrays\n",
    "    X_train = np.array(train_features)\n",
    "    X_val = np.array(val_features)\n",
    "    \n",
    "    y_train = np.zeros((len(train_labels), num_of_words), dtype = np.int8)\n",
    "    y_val = np.zeros((len(val_labels), num_of_words), dtype = np.int8)\n",
    "    \n",
    "    for example_index, word_index in enumerate(train_labels):\n",
    "        y_train[example_index, word_index] = 1\n",
    "    for example_index, word_index in enumerate(val_labels):\n",
    "        y_val[example_index, word_index] = 1\n",
    "        \n",
    "    #managing the memory\n",
    "    gc.enable()\n",
    "    del features, labels, train_features, val_features, train_labels, val_labels\n",
    "    gc.collect()\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = make_train_val(features, labels, num_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224616, 50)\n",
      "(224616, 13677)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Trained Embeddings \n",
    "\n",
    "Instead of training our own word embeddings, we'll use word embeddings that were trained on a large corpus of words. The hope is that these embeddings will generalize from the training corpus to our needs.\n",
    "\n",
    "The following code downloads 100-dimensional word embeddings and loads them into a numpy array. We'll download the pre-trained embeddings from [Stanford online library](https://nlp.stanford.edu/data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399965, 101)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import get_file\n",
    "from zipfile37 import ZipFile\n",
    "\n",
    "keras_home = 'C:\\\\Users\\\\alegzander\\\\.keras\\\\datasets\\\\'\n",
    "glove_vectors_zip = keras_home + 'glove.6B.zip'\n",
    "\n",
    "#checking if we already have the file\n",
    "if not os.path.exists(glove_vectors_zip):\n",
    "    get_file('glove.6B.zip',\n",
    "             'http://nlp.stanford.edu/data/glove.6B.zip')\n",
    "\n",
    "#checking if we have already extracted the .zip file\n",
    "glove_vectors_text = keras_home + 'glove.6B.100d.txt'\n",
    "if not os.path.exists(glove_vectors_text):\n",
    "    with ZipFile(glove_vectors_zip, 'r') as gv:\n",
    "        glove_vectors_text = gv.extract('glove.6B.100d.txt', \n",
    "                                        path = keras_home)\n",
    "        \n",
    "#loading the embedding into a numpy array\n",
    "glove = np.loadtxt(glove_vectors_text, dtype = 'str', \n",
    "                   encoding = 'utf-8')\n",
    "\n",
    "glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['over', '-0.29574', '0.35345', '0.63326', '0.19576', '-0.030256',\n",
       "       '0.54244', '-0.21091', '0.32894', '-0.48888', '0.18379', '0.24242',\n",
       "       '0.40346', '0.11973', '0.013143'], dtype='<U22')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove[74][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we separate created arrays into words and corresponding vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('over',\n",
       " array([-0.29574 ,  0.35345 ,  0.63326 ,  0.19576 , -0.030256,  0.54244 ,\n",
       "        -0.21091 ,  0.32894 , -0.48888 ,  0.18379 ,  0.24242 ,  0.40346 ,\n",
       "         0.11973 ,  0.013143,  0.24154 ]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = glove[:,0]\n",
    "vectors = glove[:,1:].astype('float')\n",
    "\n",
    "gc.enable()\n",
    "del glove\n",
    "gc.collect()\n",
    "\n",
    "words[74], vectors[74][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to keep only those words that appear in our vocabulary. For words that are in our vocabulary but don't have an embedding, they will be represented as zero vectors (a shortcoming that we can address by training our own embeddings.)\n",
    "\n",
    "In the following block we will build the embedding matrix. Each row of this matrix corresponds to the word of our vocabulary and is actually a vector representation of that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lookup = {word : vec for word, vec in zip(words, vectors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_matrix(rows = num_of_words, columns = 100):\n",
    "    \n",
    "    \"Creates the embedding matrix.\"\n",
    "    \n",
    "    embedding_matrix = np.zeros((rows, columns))\n",
    "    missing_words = 0\n",
    "\n",
    "    for i, word in enumerate(word_idx.keys()):\n",
    "\n",
    "        vec = word_lookup.get(word)\n",
    "\n",
    "        if vec is not None:\n",
    "            '''because the key of the first word in our dictionary\n",
    "            corresponds to 1 (and not to 0), we have i+1'''\n",
    "            embedding_matrix[i+1] = vec\n",
    "        else:\n",
    "            missing_words += 1\n",
    "\n",
    "    print(f'There are {missing_words} words without pretrained embeddings.')\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2941 words without pretrained embeddings.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = make_embedding_matrix(num_of_words, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.enable()\n",
    "del vectors \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each word is represented by a 100-dimensional vector. We can find the closest words to a given word in embedding space using the cosine distance. This requires first normalizing the vectors, i.e. the rows of the embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_the_embedding(embedding_matrix):\n",
    "    \n",
    "    \"\"\"Normalizers the embedding matrix vectors\"\"\"\n",
    "    \n",
    "    norm_vectors = np.linalg.norm(embedding_matrix, axis = 1).reshape((-1,1))\n",
    "    embedding_matrix = embedding_matrix/norm_vectors\n",
    "    embedding_matrix = np.nan_to_num(embedding_matrix)\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = norm_the_embedding(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_words(query, embedding = embedding_matrix,\n",
    "                      idx_word = idx_word, \n",
    "                       word_idx = word_idx, n = 10):\n",
    "    \n",
    "    \"\"\"Finds closest words to a query word in embeddings\"\"\"\n",
    "    \n",
    "    idx = word_idx.get(query)\n",
    "    \n",
    "    if idx is None:\n",
    "        print(f'\\'{query}\\' is not present in the vocabulary.')\n",
    "    else:\n",
    "        vec = embedding_matrix[idx]\n",
    "        if np.all(vec == 0):\n",
    "            print(f'\\'{query}\\' does not have a pretrained embedding.')\n",
    "        else:\n",
    "            distances = np.dot(embedding_matrix,vec)\n",
    "            dist_idxs = np.argsort(distances)[::-1][:n]\n",
    "            closest_dists = distances[dist_idxs]\n",
    "            closest_words = [idx_word[idx] for idx in dist_idxs]\n",
    "            \n",
    "            print(f'Closest words to \\'{query}\\': ')\n",
    "            for word, dist in zip(closest_words, closest_dists):\n",
    "                print(f'Word: {word:15} Cosine similarty: {round(dist,4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out the function defined above. It will list out 10 most similar words to a given query. There might be a litle more entries here, but it was so fun to play around with this:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest words to 'the': \n",
      "Word: the             Cosine similarty: 1.0\n",
      "Word: this            Cosine similarty: 0.8573\n",
      "Word: part            Cosine similarty: 0.8508\n",
      "Word: one             Cosine similarty: 0.8503\n",
      "Word: of              Cosine similarty: 0.8329\n",
      "Word: same            Cosine similarty: 0.8325\n",
      "Word: first           Cosine similarty: 0.821\n",
      "Word: on              Cosine similarty: 0.82\n",
      "Word: its             Cosine similarty: 0.8169\n",
      "Word: as              Cosine similarty: 0.8128\n"
     ]
    }
   ],
   "source": [
    "find_closest_words('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest words to 'neural': \n",
      "Word: neural          Cosine similarty: 1.0\n",
      "Word: neuronal        Cosine similarty: 0.6841\n",
      "Word: cortical        Cosine similarty: 0.676\n",
      "Word: plasticity      Cosine similarty: 0.6625\n",
      "Word: pathways        Cosine similarty: 0.6534\n",
      "Word: neurons         Cosine similarty: 0.6485\n",
      "Word: sensory         Cosine similarty: 0.6391\n",
      "Word: cognitive       Cosine similarty: 0.6125\n",
      "Word: brain           Cosine similarty: 0.6082\n",
      "Word: physiological   Cosine similarty: 0.6022\n"
     ]
    }
   ],
   "source": [
    "find_closest_words('neural')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest words to '.': \n",
      "Word: .               Cosine similarty: 1.0\n",
      "Word: but             Cosine similarty: 0.9049\n",
      "Word: although        Cosine similarty: 0.8812\n",
      "Word: however         Cosine similarty: 0.8778\n",
      "Word: ,               Cosine similarty: 0.8756\n",
      "Word: when            Cosine similarty: 0.8729\n",
      "Word: and             Cosine similarty: 0.8717\n",
      "Word: though          Cosine similarty: 0.8691\n",
      "Word: it              Cosine similarty: 0.8654\n",
      "Word: this            Cosine similarty: 0.8653\n"
     ]
    }
   ],
   "source": [
    "find_closest_words('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest words to 'differential': \n",
      "Word: differential    Cosine similarty: 1.0\n",
      "Word: equation        Cosine similarty: 0.717\n",
      "Word: geometry        Cosine similarty: 0.7062\n",
      "Word: equations       Cosine similarty: 0.6953\n",
      "Word: nonlinear       Cosine similarty: 0.6427\n",
      "Word: linear          Cosine similarty: 0.6352\n",
      "Word: non-linear      Cosine similarty: 0.6035\n",
      "Word: voltage         Cosine similarty: 0.5948\n",
      "Word: generalization  Cosine similarty: 0.587\n",
      "Word: algebraic       Cosine similarty: 0.5805\n"
     ]
    }
   ],
   "source": [
    "find_closest_words('differential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest words to 'waves': \n",
      "Word: waves           Cosine similarty: 1.0\n",
      "Word: wave            Cosine similarty: 0.7943\n",
      "Word: tidal           Cosine similarty: 0.7426\n",
      "Word: wind            Cosine similarty: 0.726\n",
      "Word: currents        Cosine similarty: 0.7176\n",
      "Word: winds           Cosine similarty: 0.6818\n",
      "Word: storm           Cosine similarty: 0.6814\n",
      "Word: ocean           Cosine similarty: 0.6757\n",
      "Word: tides           Cosine similarty: 0.6724\n",
      "Word: tide            Cosine similarty: 0.6461\n"
     ]
    }
   ],
   "source": [
    "find_closest_words('waves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest words to 'rocket': \n",
      "Word: rocket          Cosine similarty: 1.0\n",
      "Word: missile         Cosine similarty: 0.7177\n",
      "Word: fired           Cosine similarty: 0.6951\n",
      "Word: launch          Cosine similarty: 0.6864\n",
      "Word: firing          Cosine similarty: 0.6759\n",
      "Word: launching       Cosine similarty: 0.6662\n",
      "Word: fire            Cosine similarty: 0.6538\n",
      "Word: attack          Cosine similarty: 0.6496\n",
      "Word: unmanned        Cosine similarty: 0.6344\n",
      "Word: tank            Cosine similarty: 0.6284\n"
     ]
    }
   ],
   "source": [
    "find_closest_words('rocket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest words to 'diffraction': \n",
      "Word: diffraction     Cosine similarty: 1.0\n",
      "Word: x-ray           Cosine similarty: 0.6791\n",
      "Word: fluorescence    Cosine similarty: 0.6164\n",
      "Word: spectroscopy    Cosine similarty: 0.6022\n",
      "Word: gratings        Cosine similarty: 0.5913\n",
      "Word: microscopy      Cosine similarty: 0.5835\n",
      "Word: scattering      Cosine similarty: 0.5797\n",
      "Word: electron        Cosine similarty: 0.552\n",
      "Word: electromagnetic Cosine similarty: 0.5509\n",
      "Word: excitation      Cosine similarty: 0.5422\n"
     ]
    }
   ],
   "source": [
    "find_closest_words('diffraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'majestic' is not present in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "find_closest_words('majestic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dnn' does not have a pretrained embedding.\n"
     ]
    }
   ],
   "source": [
    "find_closest_words('dnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model\n",
    "\n",
    "With data encoded as integers and an embedding matrix of pre-trained word vectors, we're ready to build the recurrent neural network. This model is relatively simple and uses an LSTM cell as the heart of the network. After converting the words into embeddings, we pass them through a single LSTM layer, then into a fully connected layer with `relu` activation before the final output layer with a `softmax` activation. The final layer produces a probability for every word in the vocabulary.\n",
    "\n",
    "When training, these predictions are compared to the actual label using the `categorical_crossentropy` to calculate a loss. The parameters (weights) in the network are then updated using the Nadam optimizer with gradients calculated through backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rnn(num_of_words = num_of_words,\n",
    "            embedding_matrix = embedding_matrix):\n",
    "    \n",
    "    \"Generates an RNN with an LSTM cell and pretrained embeddings.\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #implements the pretrained embeddings\n",
    "    model.add(Embedding(input_dim = num_of_words,\n",
    "                       output_dim = embedding_matrix.shape[1],\n",
    "                       weights = [embedding_matrix],\n",
    "                       trainable = False,\n",
    "                       mask_zero = True))\n",
    "    #masking makes sure that the words that do not have \n",
    "    #pretrained embeddings are skipped and do not effect\n",
    "    #the training\n",
    "    model.add(Masking())\n",
    "    \n",
    "    #adding an LSTM layer\n",
    "    model.add(LSTM(64, dropout = 0.1, recurrent_dropout = 0.1,\n",
    "                   return_sequences = False))\n",
    "    \n",
    "    #adding a dense layer\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    #adding an output layer\n",
    "    model.add(Dense(num_of_words, activation = 'softmax'))\n",
    "    \n",
    "    #compiling the RNN\n",
    "    model.compile(optimizer = 'nadam',\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will just use the words having pretrained embeddings, without training on the words from our own vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 100)         1367700   \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 13677)             1764333   \n",
      "=================================================================\n",
      "Total params: 3,182,593\n",
      "Trainable params: 1,814,893\n",
      "Non-trainable params: 1,367,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_rnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pre-trained embeddings means we have about half the parameters to train. However, this also means that the embeddings might not be the best for our data, and there's not an insignificant number of words with no embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "We can now train the model on our training examples. We'll make sure to use early stopping with a validation set to stop the training when the loss on the validation set is no longer decreasing. Also, we'll save the best model every time the validation loss decreases so we can then load in the best model to generate predictions. Saving the model also very useful in this case, since the training can take several hours. So we can load it within seconds if we need to use it anew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_callbacks(model_name):\n",
    "    \n",
    "    \"\"\"Makes list of callbacks for training\"\"\"\n",
    "    \n",
    "    #Early Stopping: Stop training when \n",
    "    #validation loss no longer decreases\n",
    "    callbacks = [EarlyStopping(monitor = 'val_loss',\n",
    "                          patience = 5)]\n",
    "    \n",
    "    #Model Checkpoint: Save the best model on disk\n",
    "    callbacks.append(ModelCheckpoint(model_name + '.h5',\n",
    "                                    save_best_only = True,\n",
    "                                    save_weights_only = False))\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../Models/'\n",
    "model_name = 'pretrained_rnn'\n",
    "model_name = model_dir + model_name\n",
    "\n",
    "callbacks = make_callbacks(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for _ in range(3):\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs = 150, \n",
    "                        batch_size = 2048, callbacks = callbacks,\n",
    "                        validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_evaluate(model_name):\n",
    "    \n",
    "    \"\"\"Load in a trained model and evaluate with \n",
    "    log-loss crossentropy and accuracy\"\"\"\n",
    "    \n",
    "    model = load_model(model_name + '.h5')\n",
    "    evaluate = model.evaluate(X_val, y_val, batch_size = 2048)\n",
    "    \n",
    "    print(f'Crossentropy loss: {round(evaluate[0],4)}')\n",
    "    print(f'Accuracy: {round(evaluate[1]*100,2)}%')\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96265/96265 [==============================] - 55s 570us/step\n",
      "Crossentropy loss: 4.937\n",
      "Accuracy: 22.72%\n"
     ]
    }
   ],
   "source": [
    "model = load_and_evaluate(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll compare our model with two simple models: one, always guessing the most frequent word (which is `the`), and the other always making a random guess from 10 most common words. We compare with the words from the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The' accuracy: 8.72%\n"
     ]
    }
   ],
   "source": [
    "#a model always guessing the word 'the'\n",
    "\n",
    "#getting the word index for each entry in the validation set\n",
    "val_word_idx = np.argmax(y_val, axis = 1)\n",
    "\n",
    "#using the fact that 'the' has index 1, we compute the accuracy\n",
    "the_accuracy = np.mean(val_word_idx == 1)\n",
    "\n",
    "print(\"'The' accuracy: {}%\".format(round(the_accuracy*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare with the second model, we need to compute the frequencies of the most frequent words, since we'll base our random predictions using these frequencies. We'll also use the fact that tokenizer sorts words by their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: the        Frequency: 0.073\n",
      "Word: a          Frequency: 0.05\n",
      "Word: of         Frequency: 0.041\n",
      "Word: .          Frequency: 0.033\n",
      "Word: ,          Frequency: 0.031\n",
      "Word: and        Frequency: 0.026\n",
      "Word: to         Frequency: 0.024\n",
      "Word: network    Frequency: 0.016\n",
      "Word: neural     Frequency: 0.015\n",
      "Word: is         Frequency: 0.014\n"
     ]
    }
   ],
   "source": [
    "total_words = sum(word_count.values())\n",
    "\n",
    "freq_words = list(word_idx.keys())[0:10]\n",
    "\n",
    "frequencies = [word_count[word]/total_words for word in freq_words]\n",
    "frequencies = np.round(frequencies, 3)[0:10]\n",
    "\n",
    "for word, freq in zip(freq_words, frequencies):\n",
    "    print(f'Word: {word:10} Frequency: {freq}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use multinomial distribution to randomly select the outcome word. But first, we need to infer probabilities based on frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: the        Probability: 0.23\n",
      "Word: a          Probability: 0.15\n",
      "Word: of         Probability: 0.13\n",
      "Word: .          Probability: 0.1\n",
      "Word: ,          Probability: 0.1\n",
      "Word: and        Probability: 0.08\n",
      "Word: to         Probability: 0.07\n",
      "Word: network    Probability: 0.05\n",
      "Word: neural     Probability: 0.05\n",
      "Word: is         Probability: 0.04\n"
     ]
    }
   ],
   "source": [
    "k = 1/np.sum(frequencies)\n",
    "probs = np.round(frequencies*k, 2)\n",
    "for word, prob in zip(freq_words, probs):\n",
    "    print(f'Word: {word:10} Probability: {prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random guessing 3.31%\n"
     ]
    }
   ],
   "source": [
    "#a model always guessing one of the 10 most common words\n",
    "\n",
    "#getting the indices of a randomly choosen words\n",
    "random_guess = np.random.choice(range(10), len(y_val), p = probs)\n",
    "\n",
    "#getting the word index for each entry in the validation set\n",
    "val_word_idx = np.argmax(y_val, axis = 1)\n",
    "\n",
    "#comparing the outcomes\n",
    "rand_accuracy = np.mean(random_guess == val_word_idx)\n",
    "print(f'Accuracy of random guessing {round(rand_accuracy*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model outperforms both guessing models by far, with 22.27% accuracy. On the other side, \"the\" guessing has 8.72% accuracy, and random guessing based on relative word frequencies has 3.18% accuracy.\n",
    "\n",
    "Let's now see our model in action trying to predict the next word from some abstract excerpt for the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_the_label(model):\n",
    "    \n",
    "    '''Guesses the output of the abstract excerpt from the\n",
    "    validaton set'''\n",
    "    \n",
    "    num_features = len(X_val)\n",
    "    index = np.random.randint(num_features)\n",
    "    \n",
    "    \n",
    "    #validation set text\n",
    "    feat_text = ' '.join(idx_word[i] for i in X_val[index])\n",
    "    \n",
    "    \n",
    "    #predicted_label\n",
    "    orig_text = X_val[index].reshape(1,-1)\n",
    "    pred_idx = model.predict_classes(orig_text)[0]\n",
    "    pred_label = idx_word[pred_idx]\n",
    "    \n",
    "    #true_label\n",
    "    label_idx = np.argmax(y_val[index])\n",
    "    label = idx_word[label_idx]\n",
    "    \n",
    "    \n",
    "    print(f'Predticted: {feat_text} \\033[1m{pred_label}\\033[0m\\n')\n",
    "    print(f'True: \\033[1m{label}\\033[0m\\n')\n",
    "    \n",
    "    if label == pred_label:\n",
    "        print(f'\\033[1m Good guess! \\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predticted: both binary and continuously modulated energy emissions . in one embodiment , array of parallel processors exhibits behavior of cooperative-competitive neural networks . parallel bus interconnections and digital and analog processing of analog information contained in the exchanged energy emissions are employed with generally local synchronization of the processors . \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1menergy\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: the software work-around input as the output vector of the programmable logic circuit . the feedforward lam neural network checking circuit has a weight matrix whose elements are based on a set of known bad input vectors for said faulty hardware block . the feedforward lam neural network checking circuit \u001b[1mis\u001b[0m\n",
      "\n",
      "True: \u001b[1mmay\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: sensor for changes in pressure and temperature to indicate a concentration of the sensed species . an apparatus is also provided , for compensating an electrochemical sensing apparatus , comprising an electrochemical sensor , being responsive to a sensed species , and an environmental variable ; an environmental variable sensor \u001b[1m.\u001b[0m\n",
      "\n",
      "True: \u001b[1m,\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: is subjected to wavelet analysis , which transforms the dynamics of the time series of arterial blood pressure contour into multi-resolution wavelet coefficients or signatures . the processing module includes a neural network which is trained to associate the diagnostic features of the transformed arterial pressure contour embedded in the \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mcoefficients\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: . a storage device stores information representing a standard pattern of radiation images . a signal transforming device transforms the first image signal representing the radiation image into a transformed image signal representing the radiation image , which has been transformed into the standard pattern . a condition adjuster is \u001b[1ma\u001b[0m\n",
      "\n",
      "True: \u001b[1mprovided\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: the signal to estimate a set of analysis features , wherein each analysis feature defines an element of the signal and has feature values that represent parts of the signal , processing the signal to estimate input features of the signal , and processing the input features using a deep \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mneural\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: and circuits of the present invention aim to associate a norm to each component of an input pattern presented to an input space mapping algorithm based artificial neural network ann during the distance evaluation process . the set of norms , referred to as the 8220;component 8221; norms is memorized \u001b[1mto\u001b[0m\n",
      "\n",
      "True: \u001b[1min\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: group leak sensitive variables , and subgroup leak sensitive variables , and which may be automatically be obtained using a data driven approach and a leak sensitivity function . one embodiment uses artificial neural networks ann to learn the map between appropriate leak sensitive variables and the leak behavior . \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mthe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: to input the bd into the neural network ; a verification device which captures an output from the neural network to authenticate the object , wherein the neural network is a bidirectional associative memory , particularly a hopfield network , having a multiplicity of network states . the verification device \u001b[1mis\u001b[0m\n",
      "\n",
      "True: \u001b[1mis\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: a best path from the plurality of paths comprises application of fuzzy logic , using a threshold function to identify a best relative path value by providing an input to the function which is a combination of the attribute values of the elements within each path . the input to \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mthe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: a cell of mos transistors for converting a voltage into a current for forming synapses of neural nets , in particular for converting the difference between an input voltage v .sub .in and a voltage v .sub .w for weighting the synapse into a current , realized by means of \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1ma\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: as a stand alone system , with the advantage that many modules can be connected together to create a wide variety of configurations and network sizes . this modular approach results in a scaleable system that meets increased workload with an increase in parallelism and thereby avoids the usually extensive \u001b[1m.\u001b[0m\n",
      "\n",
      "True: \u001b[1mincreases\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: determines the degree of match between a respective exemplar vector and an input vector and feeds a respective primary parzen node . the exemplar and primary parzen nodes are grouped into design classes , with a sum node for each class which combines the outputs of the primary parzen nodes \u001b[1m.\u001b[0m\n",
      "\n",
      "True: \u001b[1mfor\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: plurality of interconnected units arranged in layers including an input layer and an output layer . each unit has a multiplicity of unit inputs and a set of variables for operating upon a unit inputs to provide a unit output in the range between binary 1 and binary 0. a \u001b[1mplurality\u001b[0m\n",
      "\n",
      "True: \u001b[1mplurality\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: the characteristic extraction section . finally , a normalization recognition section codes and outputs the final result by carrying out a timing normalization and a classifying process using a radial basis function rbf neural network on the basis of the voice characteristics provided by the characteristic extraction section and the \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1minformation\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: set of inputs and an output . the received code words and at least some of the output signals of the neural network neurons are connected to the inputs of the neurons , and the neurons comprise means for multiplying at least some of the neuron inputs prior to combining \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mmeans\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: circuit comprises a plurality of recognition processing units each composed of a neural network . teacher signals and information signals to be processed are supplied to a plurality of the units , individually so as to obtain output signals by executing individual learning . thereafter , the plural units are \u001b[1mused\u001b[0m\n",
      "\n",
      "True: \u001b[1mconnected\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: modules . each module comprises a plurality of neuron elements . processing the image further comprises performing a neuron state update for each module , that includes aggregating input spikes and updating neuron membrane potentials , and performing spike propagation for each module , which includes transferring spikes generated in \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1ma\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: has an input layer , a hidden layer , and an output layer . the neural network stores weight values which operate on data input at the input layer to generate output data at the output layer . an error computing unit receives the output data and compares it with \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mdesired\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: neural network that ceases training at or near the optimally trained point is presented . a neural network having an input layer , a hidden layer , and an output layer with each layer having one or more nodes is presented . each node in the input layer is connected \u001b[1mto\u001b[0m\n",
      "\n",
      "True: \u001b[1mto\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: temperature in a high temperature processing chamber . wafer temperature estimator parameters provide an estimated wafer temperature from contact-type temperature sensor measurements . the estimator parameters are refined using non-contact-type temperature sensor measurements during periods when the substrate temperature is decreasing or the heaters are off . a corresponding temperature \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mcontrol\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: are indicative of a degree of repetition of the deinterleaved symbols , a neural network for processing the plurality of output feature values according to a predetermined set of weights to produce a plurality of output rate determination values y .sub .1, y .sub .2, . . . y .sub \u001b[1m,\u001b[0m\n",
      "\n",
      "True: \u001b[1m.n\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: acquired from previous known good runs of the process tool . the fault detector notifies a process tool operator of any faults which occur thus potentially avoiding wafer scrap and potentially improving mean time between failures . the fault detector also receives notification of the occurrence of process events from \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mthe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: network after training becomes a fuzzy belief network ; the inference and weight are exchangeable , and as a result , knowledge extraction becomes simple . plann performs associative memory , supervised , semi-supervised , unsupervised learning and function relation approximation in a single network architecture . this network architecture \u001b[1mis\u001b[0m\n",
      "\n",
      "True: \u001b[1mcan\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: the electrical signals into numerical data representing an ultrasound image . a neural network connected to the image reconstructor analyzes the numerical data and an output system presents information representing the quality of the spot weld joint . the system is trained to assess the quality of spot weld joints \u001b[1m.\u001b[0m\n",
      "\n",
      "True: \u001b[1mby\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: processing system in the form of membership functions and fuzzy rules as technical information relating to a control target . according to this fuzzy model , a weight value of the connection between neurons is set and a pre-wired neural network is established . then , the data of the \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mcontrol\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: on a substrate surface , and growing a first nanowhisker via each catalytic particle . the second stage includes providing , on the periphery of each first nanowhisker , one or more second catalytic particles , and growing , from each second catalytic particle , a second nanowhisker extending transversely \u001b[1mto\u001b[0m\n",
      "\n",
      "True: \u001b[1mfrom\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: multi-dimensional data set and a corresponding set of dimensionally reduced points . thereafter , these one or more non-linear functions are used to non-linearly map additional points . the additional points may be members of the original multi-dimensional data set or may be new , previously unseen points . in \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1man\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: pertain to classes of interest are not suppressed too greatly . this is achieved by modifying the amount by which error signals , corresponding to classes which are incorrectly identified , are employed in the training process , relative to error signals corresponding to the correct class . as a \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mresult\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: of pair of sub-tables are generated and characteristic parameters are calculated for genes contained in these sub-tables . finally , for each combination a characteristic value is calculated with a decision algorithm defined in function of these parameters , by considering the genes of the combination as constituting a “gene \u001b[1mplurality\u001b[0m\n",
      "\n",
      "True: \u001b[1mnetwork”\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: determining input values describing the fill event , and then estimating a fill time using the input values . the method includes filling the apply chamber using the estimated fill time eft or within an allowable range of the eft . the input values can include a command line pressure \u001b[1mto\u001b[0m\n",
      "\n",
      "True: \u001b[1m,\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: an output unit , a main control unit , a learning storage unit , and a neural network . the neural network learns the relationship between the input value of shape data and the output value of the data on the degree of pain when a subject touches a shape \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1m.\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: neuron coupled to the input neuron with coupling coefficients determined from quantized feature quantities and a pair of output neurons coupled to respective intermediate neurons with intermediate coupling coefficients obtained by learning in which the intermediate coupling coefficients are initially set so that any object is judged to be defective \u001b[1m.\u001b[0m\n",
      "\n",
      "True: \u001b[1mand\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: to one of n target classes or classified as a counterfeit . for the n target classes n recognition units 15.1 to 15.n are used , exactly one of the n target classes being recognisable by one recognition unit 15.j using a respective feature vector agfj prepared for that class \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1m.\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: function of an error signal by means of the back-propagation method so that the regulator gradually improves its control algorithm as a result of accumulated experience . the network is implemented in software which can be developed and run on a pc with extra co-computing capability for greater execution speed \u001b[1m.\u001b[0m\n",
      "\n",
      "True: \u001b[1m.\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: target controlled variable , the fourth step of obtaining a correction amount for the virtual manipulated variable in accordance with a back propagation calculation of the second neural network model , using the error obtained in the third step , thereby correcting the virtual manipulated variable with the correction amount \u001b[1m.\u001b[0m\n",
      "\n",
      "True: \u001b[1m,\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: otherwise most probable label for input at a given position in the sequence can be used when scoring input corresponding to the next position the sequence . additional features are disclosed for training a neural network for use in tagging sequential input without using an internal representation of the neural \u001b[1mnetwork\u001b[0m\n",
      "\n",
      "True: \u001b[1mnetwork\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Predticted: an estimation error criterion . the information process either consists of a measurement process , or if the signal and measurement processes are time-variant , consists of the measurement process as well as a time variance process , that describes the time-variant properties of the signal and measurement processes . \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mthe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: characteristic features a data matrix , the data matrix is processed with a self organizing network to produce a self organizing feature space mapping . the self organizing feature space mapping is processed to produce a density characterization of the feature space mapping . the self organizing network is preferably \u001b[1mused\u001b[0m\n",
      "\n",
      "True: \u001b[1mcompletely\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: provided for distributing and storing sets of temporally ordered information in a systematic and sequential fashion . this method is based on a model of how the brain functions in the distribution and storage of temporally ordered memories , but it can also be applied to the design of new \u001b[1mdata\u001b[0m\n",
      "\n",
      "True: \u001b[1mbiological\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: volume estimating apparatus 1a estimates the traffic volumes of traffic apparatus , and a traffic flow presuming apparatus 1b presumes the traffic flows generating the estimated traffic volumes . a presumption function constructing apparatus 1c corrects the presumption functions of the traffic flow presuming apparatus 1b on actually measured traffic \u001b[1m.\u001b[0m\n",
      "\n",
      "True: \u001b[1mvolumes\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: for monitoring a voltage or current characteristic within the supply circuit and an artificial neural network trained to identify whether the detected characteristic is acceptable or harmful and adapted to produce an output accordingly . the circuit may be arranged to deliver its output to a gas discharge load and \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mthe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: more document predicate structures . a comparison of each query predicate structure with each document predicate structure is performed to determine a matching degree , represented by a real number . a multilevel modifier strategy is implemented to assign different relevance values to the different parts of each predicate structure \u001b[1m.\u001b[0m\n",
      "\n",
      "True: \u001b[1mmatch\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: . one or more of the mpps is a controllable process parameter ctpp and one of the mpps is an amount of the pollutant aop emitted by the system . a defined aop value aopv represents an objective or limit on an actual value av of the emitted aop . \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mthe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: events . the simulation needs to be compensated for the alteration so that the simulation remains unbiased . the problem of finding optimal alternations can be reduced to find optimal bias parameters for the stochastic processes . here an artificial neural network ann together with a statistical bias optimizer is \u001b[1mused\u001b[0m\n",
      "\n",
      "True: \u001b[1mused\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: correlate between the hidden layer and output layer . in a preferred embodiment , the first weighting coefficients are calculated using the following formula equ1 i is the index for nodal point in the input layer and a .sub .j , b .sub .j , and c .sub .j are \u001b[1mused\u001b[0m\n",
      "\n",
      "True: \u001b[1mall\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: value logically associated with at least one entity in the pairing is varied , adjusted , or subjected to a loosened constraint . during run-time operation a screening device can screen unsuccessful pairings and forward potentially successful pairings that meet a threshold value to the neural network . the system \u001b[1mis\u001b[0m\n",
      "\n",
      "True: \u001b[1mcan\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: that incorporates the advantages of both traditional response surface methodology rsm and neural networks is disclosed . the present invention employs a unique strategy called parameter-based partitioning of the given design space . in the design procedure , a sequence of composite response surfaces based on both neural networks and \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mpolynomial\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: . taking into account predetermined evaluation variables , an evaluation v .sub .t is determined for the state vector sv .sub .t . in addition , a chronologically following state vector sv .sub .t 1 is determined and evaluated v .sub .t 1 . on the basis of the two \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mevaluations\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: soot loading in a diesel particulate filter dpf in a vehicle exhaust system includes estimating an engine-out soot rate using a first neural network that has a first set of vehicle operating conditions as inputs . the method further includes estimating dpf soot loading using a second neural network that \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mhas\u001b[0m\n",
      "\n",
      ".........................\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    predict_the_label(model)\n",
    "    print('.........................')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the Output\n",
    "\n",
    "Now for the fun part: we get to use our model to generate new abstracts. To do this, we feed the network a seed sequence, have it make a prediction, add the predicted word to the sequence, and make another prediction for the next word. We continue this for the number of words that we want. We compare the generated output to the actual abstract to see if we can tell the difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some HTML formatting\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def header(text, color='black'):\n",
    "    raw_html = f'<h1 style=\"color: {color};\"><center>' + \\\n",
    "        str(text) + '</center></h1>'\n",
    "    return raw_html\n",
    "\n",
    "\n",
    "def box(text):\n",
    "    raw_html = '<div style=\"border:1px inset black;padding:1em;font-size: 20px;\">' + \\\n",
    "        str(text)+'</div>'\n",
    "    return raw_html\n",
    "\n",
    "\n",
    "def addContent(old_html, raw_html):\n",
    "    old_html += raw_html\n",
    "    return old_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_output(model, sequences, train_length = 50,\n",
    "                   new_words = 50, diversity = 1):\n",
    "    \n",
    "    \"\"\"Generates new apstract excerpt out \n",
    "    of output from a trained model and formats it into HTML.\"\"\"\n",
    "    \n",
    "    #choosing a random sequence from all the abstracts\n",
    "    #and choosing a random seed subsequence from it\n",
    "    seq = random.choice(sequences)\n",
    "    start_idx = random.randint(0, len(seq) - train_length - 20)\n",
    "    end_idx = start_idx + train_length\n",
    "    seed_seq = seq[start_idx : end_idx]\n",
    "    seed_text = [idx_word[i] for i in seed_seq]\n",
    "    \n",
    "    #generating new sequence of words from the seed sequence\n",
    "    gen_seq = []\n",
    "    \n",
    "    for _ in range(new_words):\n",
    "        \n",
    "        input_seq = np.array(seed_seq).reshape(1,-1)\n",
    "        \n",
    "        #predicting the probabilities for each word\n",
    "        probs = model.predict(input_seq)[0]\n",
    "        \n",
    "        #implementing the diversity parameter\n",
    "        probs = np.log(probs)/diversity\n",
    "        probs = np.exp(probs)\n",
    "        \n",
    "        #implementing softmax function\n",
    "        probs = probs/sum(probs)\n",
    "        probs = np.round(probs, 4)\n",
    "        \n",
    "        #getting the next word\n",
    "        if sum(probs[:-1]) > 1:\n",
    "            #sometimes, due to computational errors we might get\n",
    "            #sum of probabilities to be greater than 1\n",
    "            next_word = np.argmax(probs)\n",
    "        else:\n",
    "            next_word = np.random.multinomial(1,probs)\n",
    "            next_word = np.argmax(next_word)\n",
    "\n",
    "        #updating the seed sequence\n",
    "        seed_seq = seed_seq[1:] + [next_word]\n",
    "        gen_seq.append(next_word)\n",
    "        \n",
    "    \n",
    "    #getting the actual text\n",
    "    actual_seq = seq[end_idx : end_idx+new_words]\n",
    "    actual_text = [idx_word.get(i,'<-->') for i in actual_seq]\n",
    "    \n",
    "    #getting the generated text\n",
    "    gen_seq = gen_seq[:len(actual_seq)]\n",
    "    gen_text = [idx_word.get(i,'<-->') for i in gen_seq]\n",
    "    \n",
    "    \n",
    "    #HTML formatting\n",
    "    seed_html = ''\n",
    "    seed_html = addContent(seed_html, header(\n",
    "        'Seed Sequence', color='darkblue'))\n",
    "    seed_html = addContent(seed_html,\n",
    "                           box(' '.join(seed_text)))\n",
    "    \n",
    "    actual_html = ''\n",
    "    actual_html = addContent(actual_html, header('Actual', color='darkgreen'))\n",
    "    actual_html = addContent(actual_html, box(' '.join(actual_text)))\n",
    "\n",
    "\n",
    "    gen_html = ''\n",
    "    gen_html = addContent(gen_html, header('RNN Generated', color='darkred'))\n",
    "    gen_html = addContent(gen_html, box(' '.join(gen_text)))\n",
    "\n",
    "    \n",
    "    return seed_html, actual_html, gen_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's see our generator in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">fully connected neural network . each subset is formed during a different time slot of a plurality of time slots of a time multiplexing cycle of the stm neuromorphic network . in combination , the inter-nodal connection subsets implement the fully connected neural network . a method of synaptic time</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">multiplexing a neuromorphic network includes providing the neural fabric and forming the subsets of the set of inter-nodal connections .</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">series phoneme , increasing back the degraded nonlinear set , and and accomplishes length error statistics vector weight value as</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">. correlated historical values of the metric and additional related metrics cross-correlation are used as inputs to a feed-forward back propagation neural network , in order to train the network to generalize the behavior of the metric . from this generalized behavior , point-by-point threshold values are calculated . the</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">metric is monitored and the monitored values are compared with the threshold values to determine if the metric has violated its normal time-varying behavior . if so , an event is generated to notify an administrator of the error condition .</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">high model interval of the correlative weights of the network includes the customers of a row cells determined is employed by means the output processing signal from the infrared controller being processing and iteratively the highest multiprocessing data from the shape</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">passing through a sample under analysis downhole . as each filter is tilted , the color or wavelength of light passed by the filter changes . black plates are placed between the filters to isolate each filter's photodiode . the spectrometer of the present invention is suitable for use with</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">a wire line formation tester , such as the baker atlas reservation characterization instrument to provide supplemental analysis and monitoring of sample clean up . the present invention is also suitable for deployment in a monitoring while drilling environment . the present invention provides a high resolution spectometer which enables</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">the recommended is subject . the change of the corresponding of a cappi set of output represents were used by selecting a thermal value . the results of the sensors uses them a variety neural network . this sensor allows to and generate the and aperture of a 3g c</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    seed_html, actual_html, gen_html = generate_output(model, sequences)\n",
    "    display(HTML(seed_html))\n",
    "    display(HTML(actual_html))\n",
    "    display(HTML(gen_html))\n",
    "    print('..........................')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `diversity` parameter determines how much randomness is added to the predictions. If we just use the most likely word for each prediction, the output sometimes gets stuck in loops. The diversity means the predicted text has a little more variation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">a set of signal characteristics from a time domain signal based on the audio signal . the set of signal characteristics is the set of the magnitudes of the discrete fourier transform coefficients of an acquired time domain signal , or the fourier transform coefficients themselves . a classifier is</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">connected to the characteristic extraction unit . it is a two-layer neural network that uses the set of signal characteristics to accurately determine whether the acquired time domain signal represents breaking glass .</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">used to implement corresponding noise points to the second propagation process which a predetermined gradient and a coefficient generator , and the first or more an electric signal to a second of the</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">and serve as the inputs to a corresponding one of the plurality of operational amplifiers . each synapse includes a capacitor connected between ground potential and the input terminal for weighting the synapse by storing a weighting voltage applied thereto . a random access memory has digitally stored voltage values</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">for weighting all of the synapses . a plurality of digital-analog converters , one for each column of the array of synapses , are connected to the random access memory for converting the digital voltage values for weighting the synapses into analog voltage values . the digital-analog converters provide respective</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">. the k is a single neuron and a corresponding of different synapses and the spike output circuit . the memory circuits may be used to the the output signal and the output value , and the synapse of the plurality of neurons , an output of the first output</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">relationships among known variables . the predictive model is generated using historical data of delinquent debt accounts , the collection methods used to collect the debts in the accounts , and the success of the collection methods . in one embodiment , the predictive model is generated using profiles of</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">delinquent debt accounts summarizing patterns of events in the accounts , and the success of the collection effort in each account . in another embodiment , the predictive model includes a mathematical representation of the collector's notes created during the collection period for each account .</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">target data , and and the system is used to be more simpler and the relationships of data . finally and the measures of the neural network . the neural network is optimally in the data design , such as a neural network using a model</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    seed_html, actual_html, gen_html = generate_output(model, sequences,\n",
    "                                                       diversity = 0.75)\n",
    "    display(HTML(seed_html))\n",
    "    display(HTML(actual_html))\n",
    "    display(HTML(gen_html))\n",
    "    print('..........................')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Own Embeddings\n",
    "\n",
    "Now we will try training an RNN with our own embedidings. We'll also include punctuated words (e.g. `word.`) and words with capitalized first letter as a part of our vocabulary this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory management\n",
    "def clear_memory(variables):\n",
    "    gc.enable()\n",
    "    for var in ['X_train', 'X_val', 'y_train', 'y_val',\n",
    "               'idx_word', 'word_idx', 'frequencies',\n",
    "               'embedding_matrix', 'model']:\n",
    "        if var in variables:\n",
    "            del globals()[var]\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory(dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21382 unique words in the dictionary.\n",
      "There are 286322 training sequences.\n"
     ]
    }
   ],
   "source": [
    "filters = '!\"%;[\\\\]^_`{|}~\\t\\n'\n",
    "word_idx, idx_word, num_of_words, word_count, f_abstracts, sequences, features, labels = make_sequences(\n",
    "    abstracts, filters, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11980 words without pretrained embeddings.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = make_embedding_matrix(num_of_words, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21383, 100)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = make_train_val(features, labels, num_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200425, 50), (200425, 21383))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appart from training our own embeddings, we will now also change the structure of our RNN a bit. We will use bidirectional LSTM cells for our RNN and use adam optimzer this time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "def make_bidirectional_rnn(num_of_words = num_of_words,\n",
    "            embedding_matrix = embedding_matrix):\n",
    "    \n",
    "    \"Generates a bidirectional RNN with an LSTM cell.\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #implements the pretrained embeddings and additionally\n",
    "    #trains the embeddings for the words from our vocabulary\n",
    "    model.add(Embedding(input_dim = num_of_words,\n",
    "                       output_dim = embedding_matrix.shape[1],\n",
    "                       weights = [embedding_matrix],\n",
    "                       trainable = True))\n",
    "    \n",
    "    #adding a bidirectional LSTM layer\n",
    "    model.add(Bidirectional(LSTM(64, dropout = 0.1, \n",
    "                                 recurrent_dropout = 0.1, \n",
    "                                 return_sequences = False)))\n",
    "    \n",
    "    #adding a dense layer\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    #adding an output layer\n",
    "    model.add(Dense(num_of_words, activation = 'softmax'))\n",
    "    \n",
    "    #compiling the RNN\n",
    "    model.compile(optimizer = 'adam',\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 100)         2138300   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 21383)             2758407   \n",
      "=================================================================\n",
      "Total params: 4,997,699\n",
      "Trainable params: 4,997,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_bidirectional_rnn(num_of_words, embedding_matrix)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now it's time to train the new model. The training will take longer this time, since we're now training our embeddings as well, so we have more parameters to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../Models/'\n",
    "model_name = 'bidir_rnn'\n",
    "model_name = model_dir + model_name\n",
    "callbacks = make_callbacks(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for _ in range(3):\n",
    "\n",
    "    history = model.fit(X_train, y_train, batch_size = 2048,\n",
    "                        epochs = 150, callbacks = callbacks,\n",
    "                        validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85897/85897 [==============================] - 75s 875us/step\n",
      "Crossentropy loss: 5.5816\n",
      "Accuracy: 25.18%\n"
     ]
    }
   ],
   "source": [
    "model = load_and_evaluate(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Embeddings\n",
    "\n",
    "We can take a look at our trained embeddings to figure out the closest words in the new embedding space. These embeddings are trained for our task, which means they will differ from the pre-trained versions. But first, we need to normalize the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model):\n",
    "    \n",
    "    embedding_layer = model.get_layer(index = 0)\n",
    "    embedding_matrix = embedding_layer.get_weights()[0]\n",
    "    \n",
    "    vec_norms = np.linalg.norm(embedding_matrix, axis = 1).reshape((-1,1))\n",
    "    embedding_matrix = embedding_matrix/vec_norms\n",
    "    embedding_matrix = np.nan_to_num(embedding_matrix)\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = get_embeddings(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest words to 'the': \n",
      "Word: the             Cosine similarty: 1.0\n",
      "Word: said            Cosine similarty: 0.8162000179290771\n",
      "Word: processing      Cosine similarty: 0.8093000054359436\n",
      "Word: if              Cosine similarty: 0.7989000082015991\n",
      "Word: a               Cosine similarty: 0.7961000204086304\n",
      "Word: force           Cosine similarty: 0.7741000056266785\n",
      "Word: via             Cosine similarty: 0.7591000199317932\n",
      "Word: down            Cosine similarty: 0.734000027179718\n",
      "Word: for             Cosine similarty: 0.7333999872207642\n",
      "Word: uses            Cosine similarty: 0.727400004863739\n"
     ]
    }
   ],
   "source": [
    "find_closest_words('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest words to 'neural': \n",
      "Word: neural          Cosine similarty: 1.0\n",
      "Word: with            Cosine similarty: 0.8216999769210815\n",
      "Word: including       Cosine similarty: 0.7551000118255615\n",
      "Word: structure       Cosine similarty: 0.7233999967575073\n",
      "Word: polynomial      Cosine similarty: 0.7199000120162964\n",
      "Word: time            Cosine similarty: 0.7196999788284302\n",
      "Word: estimated       Cosine similarty: 0.7184000015258789\n",
      "Word: of              Cosine similarty: 0.7120000123977661\n",
      "Word: image           Cosine similarty: 0.7116000056266785\n",
      "Word: that            Cosine similarty: 0.7088000178337097\n"
     ]
    }
   ],
   "source": [
    "find_closest_words('neural')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the new model in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predticted: Such preprocessing phase applies a genetic algorithm to populations of prediction algorithms which vary as to number and content of input variables, where the prediction algorithms representing the selections of input variables which have the best testing performances and the minimum input variables are promoted for the processing of the \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mnew\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: hands and internal hand control system from the muscular level through the intrafusal fiber system of the neural network is considered in creating the robot and method of operation of the present invention. Therefore, the surgery is not slowed down as in the art, because the surgeon is in conscious \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1mand\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: program product generates self-organizing layouts of process diagrams. Initial weight vectors are distributed uniformly within boundaries of regions in the process diagram. A spatial input vector is randomly generated within the boundaries of each region. In each region in the process diagram, a closest graphical node is found, and a \u001b[1mvector\u001b[0m\n",
      "\n",
      "True: \u001b[1mposition\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: during various phases of, and at various locations in, the combustion process. Other forms of sensors monitor and generate data signals defining selected parameters of the combustion process, such as air flow, fuel flow, turbulence, exhaust and inlet valve openings, etc. In a preferred form, a neural networks initially processes \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mthe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: within the processing apparatus. The apparatus includes a neural network having two-dimensional layers connected to form a feed-forward systolic array. Each two dimensional layer includes a feature extraction layer connected with a positional error absorbing layer. A host system provides inputs to the network. Each layer within the network includes \u001b[1ma\u001b[0m\n",
      "\n",
      "True: \u001b[1mprocessing\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: sequence of predicted feature vectors (A(t+1, s, n) and a sequence of new state vectors (h(t+1, s, n)). The recognized pattern is selected from one of the reference patterns that minimizes a prediction error between the time sequence of the input feature vectors and the time sequence of the predicted \u001b[1mimage\u001b[0m\n",
      "\n",
      "True: \u001b[1mfeature\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: time. The CIP 10 also includes a manager 16 and an input-output transducer 12 that may be used for input-output refinement. These components allow the computing capacity of the multi-kernel array 14 to be reassigned in response to measured performance or other factors. The output feature values 46 computed by \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mthe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: decay constant, and a formation-to-borehole amplitude ratio for each of the pair of detectors. From these values a trained neural network produces intrinsic values of a formation macroscopic thermal neutron absorption cross section, a formation porosity, and a borehole fluid cross section. A log is generated of these intrinsic values \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mversus\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: local signals to generate global signals that are merged in an on-chip common communication bus shared by all neurons of the chip. The R/W memory block, the neurons and the OR circuit form an artificial neural network having high flexibility due to this dual mode feature which allows to mix \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1msingle\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: craft (8,10), land based vehicles (12), vessels at sea or fixed structures (14) detect dangers using conventional scanners and transmit information signals describing the dangers to a control center (2) which analyzes the data and determines the degree of danger and its geographic extent. The center generates a danger warning \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1mand\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: reference pattern is defined by a sequence of state models, successively supplied with the time sequence of the input feature vectors and with a sequence of preceding state vectors (h(t, s, n)). The sequence of the state models produces a time sequence of predicted feature vectors (A(t+1, s, n) and \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1ma\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: least four Boolean functions are selected from sixteen possible Boolean functions that can represent input vectors to the respective pair of artificial neurons. A count for each of the at least four Boolean functions is also provided. The count represents a number of occurrences of each of the at least \u001b[1mone\u001b[0m\n",
      "\n",
      "True: \u001b[1mfour\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: -1 parallel-connected transistors controlled respectively by the template competition nodes of all second neurons except the template competition node of itself so that the template competition node connecting with the largest template matching signal is eventually at a relatively high voltage level, and the other template competition nodes are at \u001b[1mleast\u001b[0m\n",
      "\n",
      "True: \u001b[1ma\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: with a received set of collected patient data. In contrast, a runtime neural network module that only provides real time operation of the neural network using collected patient data is located within the cardiac device module. The cardiac device module and the external processing module communicate with each other to \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mpass\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: number of synapse units per neuron unit satisfy a relation of an integer multiple. The number of regularly operating neuron units can be made equal to that of the synapse units per neuron unit, whereby it is possible to prevent the neuron units from performing meaningless operations and an efficient \u001b[1mmanner.\u001b[0m\n",
      "\n",
      "True: \u001b[1mneural\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: The synapse chip can be configured to include an input layer comprising a plurality of input electrodes and an output layer comprising a plurality of output electrodes, such that the output electrodes are located perpendicular to the input electrodes. A gap is generally formed between the input layer and the \u001b[1moutput\u001b[0m\n",
      "\n",
      "True: \u001b[1moutput\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: A method for linearization of feedback in neural networks, and a neural network incorporating the feedback linearization method are presented. Control action is used to achieve tracking performance for a state-feedback linearizable, but unknown nonlinear control system. The control signal comprises a feedback linearization portion provided by neural networks, plus \u001b[1ma\u001b[0m\n",
      "\n",
      "True: \u001b[1ma\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: of the simulated scorecard. The squashing function includes a control variable for controlling the steepness of the response to the squashing function's input so that during training of the neural model the steepness can be controlled. The output of the neural model represents the score of the simulated scorecard. The \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mneural\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: The method (250) also includes inputting (266) nominal critical dimension data corresponding to the fabricated features on the substrate (212) to the neural network (208) and determining (268) the effective aberrations of the imaging system associated with the lithography system used to fabricate the features (220) using the neural network \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1m(208).\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: and an interface load (IL) for a radio network (RN) (or cell sector of an RN) are determined. Extensive information associated with the RN is collected and neural networks analysis is employed to reduce the information to a manageable set including the specific information associated with ECC and IL. The \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mreduced\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: and error spatial light modulator (5). The error modulator (5) is then controlled in accordance with the difference between a target output vector and the output vector from the transducer (5), and modulates an update beam (11) which then passes through the input modulator (1) and onto the weight modulator \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1m(3).\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: for training the neural network. The trained neural network is embedded in a controller and acts as the virtual sensor to monitor engine parameters which are difficult to measure or for which conventional physical sensors do not currently exist. The virtual sensor may be used to sense parameters such as \u001b[1ma\u001b[0m\n",
      "\n",
      "True: \u001b[1min-cylinder\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: are described to train a model using machine learning (e.g., a convolutional neural network) using training images. The model is then used to localize text in a subsequently received image, and may do so automatically and without user intervention, e.g., without specifying any of the edges of a bounding box. \u001b[1mIn\u001b[0m\n",
      "\n",
      "True: \u001b[1mIn\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: the main multi-value teacher signal, so as to compensate the multi-value errors involved in the multi-value output signal of the main neural network 16 by the multi-value output signal of the sub neural network 18 derived through a multi-value threshold means 19. A desired multi-value output signal of the parallel \u001b[1mcircuit\u001b[0m\n",
      "\n",
      "True: \u001b[1mmulti-value\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: system according to the present invention includes a memory circuit for storing neuron output values, connection weights, the desired values of outputs, and data necessary for learning an input/output circuit for writing or reading data in or out of said memory circuit a processing circuit for performing a processing for \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mdetermining\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: and, if required, an ancillary filter for providing the primary filter's estimation error statistics. The primary and ancillary filters each comprise an artificial recurrent neural network (RNN) and at least one range extender or reducer. Their implementation results in the filtering apparatus. Many types of range extender and reducer are \u001b[1mused\u001b[0m\n",
      "\n",
      "True: \u001b[1mdisclosed,\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: connective tissue as a meat probe passes by such tissue during either insertion or removal of the meat probe from the meat. The data processor also collects and calculates feature variables based on the data collected during the insertion and removal of the meat probe, and through the use of \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1martificial\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: neuron of said RNN. A range extender transforms dynamically outputs of at least one output neuron of said RNN into at least one component of the outward output process. There are many types of range extender and reducer, which have different degrees of effectiveness and computational costs. For a neural \u001b[1mnetwork\u001b[0m\n",
      "\n",
      "True: \u001b[1msystem\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: system. At least one analytic algorithm for enhanced back-propagation neural network processing is performed by a computer, wherein the analytic algorithm for enhanced back-propagation neural network processing includes SQL statements performed by the relational database management system directly against the relational database and programmatic iteration. The analytic algorithm for enhanced \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mback-propagation\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: an engine, an air/fuel ratio estimating unit for receiving a plurality of physical values detected by the state detecting means as input parameters and for estimating the air/fuel ratio using a neural network, and a compensatory fuel amount calculating unit for calculating a compensatory fuel amount for the injected fuel \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1mamount\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: in response to these inputs which is indicative of the known joint condition. Once trained, the adaptive interpreter can then interpret this set of parameters for an unknown joint to generate a fast and reliable diagnosis. The result is a non-subjective joint disorder classification system that can be utilized by \u001b[1mthe\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True: \u001b[1mpersons\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: a window for introduction of electromagnetic energy into the sample tank for analyzing a formation fluid sample down hole or at the surface without disturbing the sample. Near infrared, mid infrared and visible light analysis is performed on the sample to provide a downhole in situ or surface on site \u001b[1min\u001b[0m\n",
      "\n",
      "True: \u001b[1manalysis\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: controller, a sigmoid activation ROM look-up-table, a plurality of neuron state registers, and a synaptic weight RAM. The neuroprocessor reduces the number of neurons required to perform the task by time multiplexing groups of neurons from a fixed pool of neurons to achieve the successive hidden layers of a recurrent \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mnetwork\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: hidden layer output signals may be augmented by weight factors, and the augmented hidden layer output signals may be linearly combined to produce real and imaginary components of an estimated jammer signal. A linear filter function may be executed for the components of the jammer signal, and to produce a \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mnonlinear\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: phoneme recognition neural network system as described herein utilizes a-priori phonetic knowledge. Phonetics is concerned with the configuration of the human vocal tract while speaking and acoustic consequences on vocalizations. While similar sounding phonemes are difficult to detect and are frequently misidentified by previously known neural networks, phonetic knowledge gives \u001b[1ma\u001b[0m\n",
      "\n",
      "True: \u001b[1minsight\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: for automatically determining the present will of a human subject. The characteristic values of the subject are detected and output signals corresponding to the detected characteristic values are produced, amplified and digitized. A set of state variables for each selected frequency sub-band of a selected frequency band for each of \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mthe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: as a data array, for a prespecified application to indicate output categories characteristic of the processing for that application. In the invention, an input stage accepts the data array and converts it to a corresponding internal representation, and a data preprocessor analyzes the data array based on a plurality of \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mfeature\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: neural network, is preferably used. The prediction engine is trained using the existing detailed models of network devices. Once trained, the prediction engine is used to model the generic process, and the protocol model that includes the generic component is used in lieu of the detailed models, thereby saving substantial \u001b[1maccuracy\u001b[0m\n",
      "\n",
      "True: \u001b[1mprocessing\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: serial-in-parallel-out difference-square accumulator having a first input coupled to one of the interconnected switches and generating a first output (b) an activation function for transforming the first output of the serial-in-parallel-out difference-square accumulator and generating a second output and (c) a parallel-in-serial-out shift register for shifting out the second output \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mof\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: system for analyzing a patient's breaths. The arrangement may include a sensor and a processor. The sensor detects data corresponding to a patient's breathing patterns over a plurality of breaths. The processor separates the detected data into data segments corresponding to individual breaths. Then, the processor analyzes the data segments \u001b[1min\u001b[0m\n",
      "\n",
      "True: \u001b[1musing\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: constructed (programmed), trained on historical data, and used to predict any of (1) optimal patient dosage of a single drug, (2) optimal patient dosage of one drug in respect of the patient's concurrent usage of another drug, (3a) optimal patient drug dosage in respect of diverse patient characteristics, (3b) sensitivity \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mof\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: a deep neural network to generate an alternative representation of the input image, wherein the deep neural network comprises a plurality of subnetworks, wherein the subnetworks are arranged in a sequence from lowest to highest, and wherein processing the data characterizing the input image using the deep neural network comprises \u001b[1ma\u001b[0m\n",
      "\n",
      "True: \u001b[1mprocessing\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: synapse of a physicallelectromechanical neural network. A physical/electromechanical neural network implemented as an adaptive neural network can be provided, which includes one or more neurons and one or more synapses thereof, wherein the neurons and synapses are formed from a plurality of nanoparticles disposed within a dielectric solution in association \u001b[1mwith\u001b[0m\n",
      "\n",
      "True: \u001b[1mwith\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: for estimating an output parameter from an input data set that is composed of a plurality of input parameters and that is obtained whenever sampling time series input data. In this output parameter estimation apparatus, a fuzzy inference rule is used to calculate a fitness degree of the input data \u001b[1mto\u001b[0m\n",
      "\n",
      "True: \u001b[1mset\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: 1) performs high-level functions. It comprises up to O hierarchically stacked neural networks, Nm, . . . , Nm+(O−1), where m denotes the stage/order tasks performed in the first neural network, Nm, and O denotes the highest stage/order tasks performed in the highest-level neural network. The type of processing actions \u001b[1mare\u001b[0m\n",
      "\n",
      "True: \u001b[1mperformed\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: representing different sentiments can be received. Each expression in the sentiment dictionary can be mapped to a corresponding sentiment value. An overall sentiment for the electronic communication can be determined using the sentiment dictionary. Training data usable for training the neural network can be automatically constructed based on the overall \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1msentiment\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: processor. The processor may execute the machine readable instructions to: input the sequence of temporal signals relating to the unrecognized event to a recurrent neural network transform the sequence of temporal signals relating to the unrecognized event to a neural output relating to the unrecognized event with the recurrent neural \u001b[1mnetwork\u001b[0m\n",
      "\n",
      "True: \u001b[1mnetwork\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: application program. The neural network shell contains a set of utility programs that transfers data into and out of a neural network data structure. This set of utility programs allows an application program to define a new neural network model, create a neural network data structure, train a neural network, \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1mand\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: a region of lesion skin and a region of normal skin. A first convolutional neural network is trained according to an interior of the region of lesion skin using each of the plurality of dermatoscopic images. A second convolutional neural network is trained according to a boundary between the region \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mof\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: determines estimates of actual measured values a residual vector is determined from the auto-associative neural network a fault diagnostic is performed on the residual vector and a change of the operation of the asset system is determined by analysis of the residual vector. An alert is provided if necessary. A \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1msmart\u001b[0m\n",
      "\n",
      ".........................\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    predict_the_label(model)\n",
    "    print('.........................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">transformation with one or more of the wavelet signatures based on filters and/or thresholds, and may determine that the wavelet transformation indicates that the patient of the physiological signal has a physiological condition indicated by the related wavelet signature. In some embodiments, the pulse oximeter system may use previous analyses</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">in a neural network to update the library. Further, non-physiological components of the wavelet transformation may also be identified and removed.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">as at least one of detection for all the said neural network as to a neural network. The potential of a</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">neural network, is disclosed. The method includes using the data classifier to generate elements of result output data in response to elements of test input data, generating a measure of difference between each element of test output data and each corresponding element of result output data, associating the measures of</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">difference with categories corresponding to different values of measures of difference, and, based on the number of measures of difference associated with the categories, generating a performance measure of the data classifier.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">the input of the hidden network, and outputting a template values. Supplying value for those data and the output node signals is that corresponding to the synapses multiprocessing network feedback 88 for</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">implemented by means of exchange of signals which carry information in the form of both binary and continuously modulated energy emissions. In one embodiment, array of parallel processors exhibits behavior of cooperative-competitive neural networks. Parallel bus interconnections and digital and analog processing of analog information contained in the exchanged energy</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">emissions are employed with generally local synchronization of the processors. Energy emission and detection is modulated as a function of a random code.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">field with pseudorandom charge modulators corresponding to charge (dual In the neural network can also be programmed into said network to receive an</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    seed_html, actual_html, gen_html = generate_output(model, sequences)\n",
    "    display(HTML(seed_html))\n",
    "    display(HTML(actual_html))\n",
    "    display(HTML(gen_html))\n",
    "    print('..........................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">213. Then, each audio frame is assigned a phonetic representation 203 and a target acoustic representation 208, where the phonetic representation 203 is a binary word that represents the phone and articulation characteristics of the audio frame, while the target acoustic representation 208 is a vector of audio information such</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">as pitch and energy. After training, the neural network 106 is used in conversion of text into speech. First, text that is to be convened is translated to a series of phonetic frames 401 of the same form as the phonetic representations 208 and having the fixed duration 213. Then</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">for example, the multi-spectral state of each neuron network to be utilized to determine the machine and classification memory or out the control device for providing the program of a number of learning decisions. In the analysis is also described. The use of the feedback associated with the personalized of</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">and video processing. The system processes an image with a spiking neural network simulator having a plurality of inter-connected modules. Each module comprises a plurality of neuron elements. Processing the image further comprises performing a neuron state update for each module, that includes aggregating input spikes and updating neuron membrane</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">potentials, and performing spike propagation for each module, which includes transferring spikes generated in a current time step. Finally, an analysis result is output.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">and a plurality of languages. The neural network outputs elements to learn or a second output for an output signal for the memory may</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">neurons, a plurality of incoming electronic axons, and multiple electronic synapses interconnecting the incoming axons to the neurons. Each neuron has a corresponding outgoing electronic axon. In one embodiment, zero or more sets of connectivity neural core circuits interconnect outgoing axons in a functional neural core circuit to incoming axons</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">in the same functional neural core circuit. In another embodiment, zero or more sets of connectivity neural core circuits interconnect outgoing and incoming axons in a functional neural core circuit to incoming and outgoing axons in a different functional neural core circuit, respectively.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">in the template competition core with the multiple stages, and thus connected which are associated with adjacent component signals for the same neuron. There are connected in a single multiple neural network. At least one neuron may be formed in each of a</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    }
   ],
   "source": [
    "#changing the diversity\n",
    "for _ in range(3):\n",
    "    seed_html, actual_html, gen_html = generate_output(model, sequences,\n",
    "                                                       diversity = 0.75)\n",
    "    display(HTML(seed_html))\n",
    "    display(HTML(actual_html))\n",
    "    display(HTML(gen_html))\n",
    "    print('..........................')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the Training Sequence\n",
    "\n",
    "We can try and see how our bidirectional model responds if we reduce the training sequence size. This actually means that we are going to have larger training sets for our model to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21382 unique words in the dictionary.\n",
      "There are 393004 training sequences.\n"
     ]
    }
   ],
   "source": [
    "clear_memory(dir())\n",
    "\n",
    "filters = '!\"%;[\\\\]^_`{|}~\\t\\n'\n",
    "word_idx, idx_word, num_of_words, word_count, f_abstracts, sequences, features, labels = make_sequences(\n",
    "    abstracts, filters, training_length = 20, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11980 words without pretrained embeddings.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = make_embedding_matrix(num_of_words, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((275102, 20), (275102, 21383))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = make_train_val(features, labels, num_of_words)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../Models/'\n",
    "model_name = 'short_bidir_rnn'\n",
    "model_name = model_dir + model_name\n",
    "callbacks = make_callbacks(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for _ in range(3):\n",
    "\n",
    "    history = model.fit(X_train, y_train, batch_size = 2048,\n",
    "                    epochs = 150, callbacks = callbacks,\n",
    "                    validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117902/117902 [==============================] - 80s 677us/step\n",
      "Crossentropy loss: 5.3962\n",
      "Accuracy: 22.85%\n"
     ]
    }
   ],
   "source": [
    "model = load_and_evaluate(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy-wise, our previous model with logner training sequences performed better. But let's see how this model behaves when it come to generating new texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predticted: to each of the object locations and training the neural network on the training image using the optimal set of \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1massignments.\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: least one of the vectors of the second collection with a corresponding vector of a fifth collection. Using a forecasting \u001b[1msystem\u001b[0m\n",
      "\n",
      "True: \u001b[1mconfiguration,\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: of the optical emission trace. The back-propagation method is used to train the network. More generally, a neural network can \u001b[1mbe\u001b[0m\n",
      "\n",
      "True: \u001b[1mbe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: mixed together in changing interference environments with very minimal assumption on the original signals. The system of this invention has \u001b[1ma\u001b[0m\n",
      "\n",
      "True: \u001b[1mpractical\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: speech post classifier such as a neural network. In one embodiment, a fuzzy Viterbi algorithm is used with the hidden \u001b[1mlayer\u001b[0m\n",
      "\n",
      "True: \u001b[1mMarkov\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: system further provides effective recognition of patterns that are partially present in the input signal, or that are partially occluded, \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1mand\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: so as to establish an outlet water COD predicted value, (3) comparing the outlet COD predicted value with the outlet \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1mwater\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: amplitude and a constant decay time for each axis at the time of passage from one quadrant to another, with \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mthe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: generated in the material. The processor measures the times taken for each output signal corresponding to artificially induced acoustic emission \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1mevents,\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: at least one delayed version of this EGM signal, formed by a second sequence of collected samples distinct from the \u001b[1minput\u001b[0m\n",
      "\n",
      "True: \u001b[1mfirst\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: fully-connected neural network mode, or in cooperative, competitive neural network mode. Feature vector or two-dimensional image data is retrieved from \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mexternal\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: neural network to learn the production rules of its associated subsystem, and computing exact or interpolated outputs from a given \u001b[1mset\u001b[0m\n",
      "\n",
      "True: \u001b[1mset\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: populations of testing and training subsets used in connection with a given prediction algorithm. In exemplary embodiments the prediction algorithm \u001b[1mis\u001b[0m\n",
      "\n",
      "True: \u001b[1moperated\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: input terminals of said each synapse circuit being constructed of terminals which turn on and off the respective current switches \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1mand\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: vectors then each pass to separate self-organizing neural network classifiers. The classifiers compare the feature vectors to templates corresponding to \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mrespective\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: the region defining a pattern recognition parameter common to all the trace portions, and determining the value of the parameters \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mfor\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: variables. The term generators 3 each have four sub-apparatuses: a data-limiting apparatus 31, a minimum value calculation apparatus 32, a \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mnon-important,\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: determine a control signal so that the CPU can be controlled to raise or lower its operating frequency. In addition, \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mif\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: signal change for equalizing the first and second input terminals for a predetermined period, and a circuit for activating the \u001b[1moutput\u001b[0m\n",
      "\n",
      "True: \u001b[1msense\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: that induces the network to classify whether the speech samples come from the same speaker. The weights from the tied \u001b[1mtime\u001b[0m\n",
      "\n",
      "True: \u001b[1mweight\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: is determined by calculating a similarity coefficient, based on the structures of each pair of query predicates and document predicates. \u001b[1mThe\u001b[0m\n",
      "\n",
      "True: \u001b[1mDocuments\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: a plurality of layers. A subset of the layers are interconnected between processing nodes such that activations are fed forward \u001b[1mto\u001b[0m\n",
      "\n",
      "True: \u001b[1macross\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: state variables s(t) that are not variable. A control network (74) is provided that accurately models the plant (72). The \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1moutput\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: irregular at a glance, by the deterministic method. A neural network which connects a plurality of neurons to each other \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mis\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: has a plurality of neurons. The network comprises a RAM, which provides a plurality of storage locations for each of \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mthe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: methods comprise transmitting impulses of energy non-invasively to selected nerve fibers, particularly those in a vagus nerve. The methods provide \u001b[1ma\u001b[0m\n",
      "\n",
      "True: \u001b[1mdamaged\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: items as bounding box information, describing the size and position of the block, and font information, describing the size and \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mtype\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: a spectral transmittance distribution is estimated by linear polynomial approximation using the transformed characteristic parameters, eigenvectors obtained by the multivariate \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1manalysis,\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: between the neurons in accordance with an energy function expressed in the form of a sum of a constrain condition \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mand\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: as a parabolic transfer function, to produce a neural node with a deterministic chaotic response suitable for quickly and globally \u001b[1ma\u001b[0m\n",
      "\n",
      "True: \u001b[1msolving\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: is digitized and passed recursively through a digital difference filter to produce a multiplicity of filtered output waveforms. These waveforms \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mare\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: solutions includes a niche circuit element, such as complementary low threshold Schottky barrier diode pairs (SBD) made by selected metal \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1mbarrier\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: unit for rear seats of the vehicle. The front and rear air conditioning units are controlled by an air conditioning \u001b[1mdevice\u001b[0m\n",
      "\n",
      "True: \u001b[1mECU.\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: amplifier when the error meets the criterion next, solve the pre-distortion algorithm of the RF power amplifier with said model \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mand\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: a module for determining a global difference measure and a global similarity measure for each load curve of each selected \u001b[1mvalue\u001b[0m\n",
      "\n",
      "True: \u001b[1mdata\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: single layer simultaneously receives analog signal from an analog bus and carries out a parallel operation in the same time \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mperiod\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: within which the servomechanism will reach the desired position plus a deceleration time period within the positioning time period upon \u001b[1mthe\u001b[0m\n",
      "\n",
      "True: \u001b[1mthe\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: function evaluates a beneficial system behavior of the technical system to be modeled, and thereby intensifies or increases the weighting \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1msettings\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: region obtained from the literal region extracting device (5). An image emphasis device is provided to emphasize the literal image \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1m(571)\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: trains a neural network based on the labeled plurality of image pairs, to predict whether an image pair depicts the \u001b[1mimage\u001b[0m\n",
      "\n",
      "True: \u001b[1msame\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: rectifier and a filter, producing a direct current signal proportional to the magnitude ##EQU2## This signal is compared with a \u001b[1mneural\u001b[0m\n",
      "\n",
      "True: \u001b[1mdirect\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: circuit further comprises a control module for reconfiguring the synapse array. The control module comprises a global final state machine \u001b[1mand\u001b[0m\n",
      "\n",
      "True: \u001b[1mthat\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: waveform, generating a first posterior probability vector for a first feature vector using a first neural network, determining whether one \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mof\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: is sent to a rule-based algorithm which attempts to classify the statement type. In another embodiment, the smoothed pitch contour \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mis\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: x-ray chest image and CT images merged as inputs to a common classifier, with the output of the common classifier \u001b[1mto\u001b[0m\n",
      "\n",
      "True: \u001b[1mindicating\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: of how the brain functions in the distribution and storage of temporally ordered memories, but it can also be applied \u001b[1mto\u001b[0m\n",
      "\n",
      "True: \u001b[1mto\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predticted: apparatus of designing a set of wavelet basis trained to fit a particular problem. The method and apparatus include constructing \u001b[1ma\u001b[0m\n",
      "\n",
      "True: \u001b[1ma\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n",
      "Predticted: into a plurality of voice parameters including frequency components, a neural network for transforming at least some of the separated \u001b[1mof\u001b[0m\n",
      "\n",
      "True: \u001b[1mfrequency\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: representative of many process periods of one or more decarburization operations for providing an oxygen count for a preselected gas \u001b[1msignal\u001b[0m\n",
      "\n",
      "True: \u001b[1mratio\u001b[0m\n",
      "\n",
      ".........................\n",
      "Predticted: on recent post-synaptic activity of neighboring neurons. Apparatus and methods for simplifying training of the devices are also disclosed, including \u001b[1ma\u001b[0m\n",
      "\n",
      "True: \u001b[1ma\u001b[0m\n",
      "\n",
      "\u001b[1m Good guess! \u001b[0m\n",
      ".........................\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    predict_the_label(model)\n",
    "    print('.........................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">vector is inputted to a calculating unit, a neuron which responds to the input vector is retrieved in accordance with network interconnection information stored in a first storage unit and the neuron number indicating the retrieved neuron is written in a first register. The calculating unit reads out the internal</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">information of the neuron stored in a second storage unit by using the neuron number, writes it in a second register, and calculates the sum of products of the outputs of the neurons and the connection loads of synapses connected to the neurons. By repeating the sequence of operations by</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">output concatenation signal obtained and a function output signals for said photomultiplier classification circuit for each input terminal to compute the n updating of a plurality of symbols, the highest pixel range values are contained than a interconnected neurons. This comprises the function of supplying input signals in two alternate</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">least one synapse of a physicallelectromechanical neural network. A physical/electromechanical neural network implemented as an adaptive neural network can be provided, which includes one or more neurons and one or more synapses thereof, wherein the neurons and synapses are formed from a plurality of nanoparticles disposed within a dielectric solution</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">in association with one or more pre-synaptic electrodes and one or more post-synaptic electrodes and an applied electric field. At least one pulse can be generated from one or more of the neurons to one or more of the pre-synaptic electrodes of a succeeding neuron and one or more post-synaptic</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">until a neural network 2 or construct an output group, is used to outputs the determined Hopfield neural network is shared by M intermediate cell are input to avoid o whether a post-synaptic state. The values selectively coupled to each node which multiprocessing is accomplished by a basic gate across</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">represents a detected object with a feature vector derived from the return signals acquired by an array of N transceivers operating in multistatic mode. The classification system generates the feature vector by transforming the real-valued return signals into complex-valued spectra, using, for example, a Fast Fourier Transform. The classification system</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">then generates a feature vector of singular values for each user-designated spectral sub-band by applying a singular value decomposition (SVD) to the N×N square complex-valued matrix formed from sub-band samples associated with all possible transmitter-receiver pairs. The resulting feature vector of singular values may be transformed into a feature vector</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">takes can analyze and even neglecting the VPCS and by-products. The system of the neural network, begins tested by mixtures of units such that receives multiprocessing networks can receive efficient paradigm in i, elements may directly sources in real-time. Only Mean rays, or the unknown performance including a user. The</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    seed_html, actual_html, gen_html = generate_output(model, sequences)\n",
    "    display(HTML(seed_html))\n",
    "    display(HTML(actual_html))\n",
    "    display(HTML(gen_html))\n",
    "    print('..........................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">pulmonary wedge pressure wherein a non-occluded pulmonary artery blood pressure measurement is utilized to directly estimate the pulmonary wedge pressure. A neural network is trained with occlusion-obtained data, whereafter the trained coefficients are utilized to implement the wedge pressure estimator. A flow-directed catheter is utilized to transduce the pressure waveform,</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">which is then input to the processing computer through a analog-to-digital data acquisition board. The data is preprocessed in the computer in order to present the neural network with 11 samples of blood pressure data and 11 samples of time-correlated first derivatives of the blood pressure data as well as</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">for the received removal of the matrix. A control device multiprocessing rule is configured to reduce the molten flap scale person. If both a resultant present invention determines time in the pixel of the production changes. water impedance based on the REM surface multiprocessing environment. One process can be analyzed</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">Neural Networks with specific circuits to emulate or to implement a self-learning data processor similar to or derived from the neurons and synapses of human or animal brains, (vii) analog circuits and functional blocks from simple to the complicated including but not limited to power conversion, control and management either</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">based on charge pumps or inductors, sensor signal amplifiers and conditioners, interface drivers, wireline data transceivers, oscillators and clock synthesizers with phase and/or delay locked loops, temperature monitors and controllers all the above are built from discrete components to all grades of VLSI chips. Solar photovoltaic electricity conversion, bio-lab-on-a-chip, hyperspectral</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">two optical frames for use of the attention that includes a variety of tracking information. This embodiments such as a trial list of real neural network, and a local attenuation in response in response to each time and at least one image obtained by the primary analyzer for a nonlinear</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkblue;\"><center>Seed Sequence</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">template pattern is applied to the feature representation field, and a match between the template and the input is determined. If the angle between the template vector and a vector within the representation field is too great, the selected category is reset. Otherwise the category selection and template pattern are</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkgreen;\"><center>Actual</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">adapted to the input pattern as well as the previously stored template. A complex representation field includes signals normalized relative to signals across the field and feedback for pattern contrast enhancement.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: darkred;\"><center>RNN Generated</center></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\">determined in an image candidate. Training of these features are identified by a multiprocessing model, to recognize the initial or high debt features containing abnormal time series of data processing and</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    seed_html, actual_html, gen_html = generate_output(model, sequences,\n",
    "                                                      diversity = 0.75)\n",
    "    display(HTML(seed_html))\n",
    "    display(HTML(actual_html))\n",
    "    display(HTML(gen_html))\n",
    "    print('..........................')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we really see that there's no significant difference over the previous model. It's then definitively better to use the model with longer training lengths, since our training set will be smaller, and take up less memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human or Machine?\n",
    "\n",
    "Now we're going to play a little game of guessing. Each time a user will be provided with three outputs: two of them will be machine generated, and the remaining one written by a human. The goal is to guess the non-artifical abstract. We'll use the second model to generate abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117902/117902 [==============================] - 82s 695us/step\n",
      "Crossentropy loss: 5.0167\n",
      "Accuracy: 25.49%\n"
     ]
    }
   ],
   "source": [
    "model_dir = '../Models/'\n",
    "model_name = 'bidir_rnn'\n",
    "model_name = model_dir + model_name\n",
    "model = load_and_evaluate(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_game_output(model, sequences, train_length = 50,\n",
    "                   new_words = 50, diversity = 1, output_words = 20):\n",
    "    \n",
    "    seq = random.choice(sequences)\n",
    "    start_idx = random.randint(0, len(seq) - train_length - 20)\n",
    "    end_idx = start_idx + train_length\n",
    "    seed_seq = seq[start_idx : end_idx]\n",
    "    seed_text = [idx_word[i] for i in seed_seq]\n",
    "    \n",
    "    \n",
    "    #getting the actual text\n",
    "    actual_seq = seq[end_idx : end_idx+new_words]\n",
    "    actual_text = [idx_word.get(i,'<-->') for i in actual_seq]\n",
    "    \n",
    "    game_texts = []\n",
    "    \n",
    "    for _ in range(2):\n",
    "    \n",
    "        gen_seq = []\n",
    "\n",
    "        for _ in range(new_words):\n",
    "\n",
    "            input_seq = np.array(seed_seq).reshape(1,-1)\n",
    "\n",
    "            #predicting the probabilities for each word\n",
    "            probs = model.predict(input_seq)[0]\n",
    "\n",
    "            #implementing the diversity parameter\n",
    "            probs = np.log(probs)/diversity\n",
    "            probs = np.exp(probs)\n",
    "\n",
    "            #implementing softmax function\n",
    "            probs = probs/sum(probs)\n",
    "            probs = np.round(probs, 4)\n",
    "            \n",
    "            \n",
    "            #getting the next word\n",
    "            if sum(probs[:-1]) > 1:\n",
    "                #sometimes, due to computational errors we might get\n",
    "                #sum of probabilities to be greater than 1\n",
    "                next_word = np.argmax(probs)\n",
    "            else:\n",
    "                next_word = np.random.multinomial(1,probs)\n",
    "                next_word = np.argmax(next_word)\n",
    "\n",
    "            #updating the seed sequence\n",
    "            seed_seq = seed_seq[1:] + [next_word]\n",
    "            gen_seq.append(next_word)\n",
    "            \n",
    "            #getting the generated text\n",
    "            gen_seq = gen_seq[:len(actual_seq)]\n",
    "            gen_text = [idx_word.get(i,'<-->') for i in gen_seq]\n",
    "        \n",
    "\n",
    "        gen_text = ' '.join(gen_text[:output_words])\n",
    "        game_texts.append(gen_text)\n",
    "        \n",
    "    \n",
    "    act_text = ' '.join(actual_text[:output_words])\n",
    "    game_texts.append(act_text)\n",
    "    \n",
    "    return game_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guessing_game(model, sequences, training_length = 50,\n",
    "                 new_words = 50, output_words = 10):\n",
    "    \n",
    "    \n",
    "    diversity = np.random.uniform(0.5, 1)\n",
    "    \n",
    "    #generating outputs using an RNN\n",
    "    game_texts = generate_game_output(model, sequences, \n",
    "                             diversity = diversity,\n",
    "                             train_length = training_length,\n",
    "                             new_words = new_words,\n",
    "                             output_words = output_words)\n",
    "    \n",
    "    \n",
    "    outputs = {'wrong1' : game_texts[0], 'wrong2' : game_texts[1],\n",
    "              'right' : game_texts[2]}\n",
    "    \n",
    "    \n",
    "    choices = ['wrong1', 'wrong2', 'right']\n",
    "    choices = shuffle(choices)\n",
    "    \n",
    "    for i in range(3):\n",
    "        #printing out all the choices\n",
    "        print(f'Output #{i+1}:')\n",
    "        print(f'{outputs[choices[i]]}\\n')\n",
    "       \n",
    "    #making the guess   \n",
    "    guess = int(input(\"Enter the option you think it's human (1-3):\"))\n",
    "    print('\\n')\n",
    "    \n",
    "    #checking the answer\n",
    "    if choices[guess-1] == 'right':\n",
    "        print(f'\\033[1mGood guess!\\033[0m\\n')\n",
    "    else:\n",
    "        print(f'\\033[1mWrong! The machine tricked you.\\033[0m')\n",
    "        print(f'The right answer is {choices.index(\"right\") + 1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output #1:\n",
      "by the first derivative to prior a neural network model\n",
      "\n",
      "Output #2:\n",
      "reduce randomness associated with other methods of similar purposes, and\n",
      "\n",
      "Output #3:\n",
      "be easily configured to discriminate the trajectories of Lyapunov resolution\n",
      "\n",
      "Enter the option you think it's human (1-3):3\n",
      "\n",
      "\n",
      "\u001b[1mWrong! The machine tricked you.\u001b[0m\n",
      "The right answer is 2\n",
      "\n",
      "Output #1:\n",
      "includes a neural network as a second neural network for\n",
      "\n",
      "Output #2:\n",
      "further includes modulating the mean neural group and the variance\n",
      "\n",
      "Output #3:\n",
      "network for generating a neural network and the internal neural\n",
      "\n",
      "Enter the option you think it's human (1-3):2\n",
      "\n",
      "\n",
      "\u001b[1mGood guess!\u001b[0m\n",
      "\n",
      "Output #1:\n",
      "input layer within a plurality of substrings and data cells\n",
      "\n",
      "Output #2:\n",
      "A second neural network using the data set of data\n",
      "\n",
      "Output #3:\n",
      "video content can be determined based at least in part\n",
      "\n",
      "Enter the option you think it's human (1-3):3\n",
      "\n",
      "\n",
      "\u001b[1mGood guess!\u001b[0m\n",
      "\n",
      "Output #1:\n",
      "for the feedback input pattern adjusted through the input vector\n",
      "\n",
      "Output #2:\n",
      "order to part to control the given signal, which is\n",
      "\n",
      "Output #3:\n",
      "accordance with a predetermined weight pattern. Each of the floating\n",
      "\n",
      "Enter the option you think it's human (1-3):3\n",
      "\n",
      "\n",
      "\u001b[1mGood guess!\u001b[0m\n",
      "\n",
      "Output #1:\n",
      "vectors to thereby identify clusters of high dimension points, and\n",
      "\n",
      "Output #2:\n",
      "value of the current values of the neural network to\n",
      "\n",
      "Output #3:\n",
      "of a neural network for performing a common neural network\n",
      "\n",
      "Enter the option you think it's human (1-3):1\n",
      "\n",
      "\n",
      "\u001b[1mGood guess!\u001b[0m\n",
      "\n",
      "Output #1:\n",
      "are set in correspondence with the moving direction of an\n",
      "\n",
      "Output #2:\n",
      "to determine the data processing unit to an adaptive neural\n",
      "\n",
      "Output #3:\n",
      "is compared with the same state of the critical distance\n",
      "\n",
      "Enter the option you think it's human (1-3):3\n",
      "\n",
      "\n",
      "\u001b[1mWrong! The machine tricked you.\u001b[0m\n",
      "The right answer is 1\n",
      "\n",
      "Output #1:\n",
      "plurality of neurons which activate and output certain data according\n",
      "\n",
      "Output #2:\n",
      "period of the input signal to determine if a function\n",
      "\n",
      "Output #3:\n",
      "layer of the neurons to be associated with a pair\n",
      "\n",
      "Enter the option you think it's human (1-3):2\n",
      "\n",
      "\n",
      "\u001b[1mWrong! The machine tricked you.\u001b[0m\n",
      "The right answer is 1\n",
      "\n",
      "Output #1:\n",
      "be used in the system of the present invention rather\n",
      "\n",
      "Output #2:\n",
      "then be processed in a trained neural network or work\n",
      "\n",
      "Output #3:\n",
      "neural network can be then mapped to the search device.\n",
      "\n",
      "Enter the option you think it's human (1-3):3\n",
      "\n",
      "\n",
      "\u001b[1mWrong! The machine tricked you.\u001b[0m\n",
      "The right answer is 1\n",
      "\n",
      "Output #1:\n",
      "are retrieved by the input of the acquired contrast vector\n",
      "\n",
      "Output #2:\n",
      "and support vector machine built into the detection hardware are\n",
      "\n",
      "Output #3:\n",
      "can be done by a variety of those scores in\n",
      "\n",
      "Enter the option you think it's human (1-3):2\n",
      "\n",
      "\n",
      "\u001b[1mGood guess!\u001b[0m\n",
      "\n",
      "Output #1:\n",
      "process with the network and processing the neural network model,\n",
      "\n",
      "Output #2:\n",
      "data and the neural network for a trained neural network\n",
      "\n",
      "Output #3:\n",
      "to assess the inputted data, and presenting a signal from\n",
      "\n",
      "Enter the option you think it's human (1-3):3\n",
      "\n",
      "\n",
      "\u001b[1mGood guess!\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    guessing_game(model, sequences, output_words = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "In this notebook, we built a recurrent neural network and used it to generate patent abstracts. Although the output is not always believable, in some instances it was very hard to distinguish human created from the machine generated parts of text (as in the guessing game). \n",
    "\n",
    "We'll list the results from the models we built:\n",
    "\n",
    "| Model Name | Pretrained Embeddings | Training Sequence Size | Optimizer | Validation Accuracy |\n",
    "|-------------|---------------|----------------|-------------|-------|\n",
    "| One-directional | Yes | 50 words | Nadam | 22.72% |\n",
    "| Bi-directional | No | 50 words  | Adam | 25.18% |\n",
    "| Short bi-directional | No | 20 words | Adam | 22.85% |\n",
    "\n",
    "The best performing model in terms of the validation data appears to be the bi-directional model with training sequence of 50 words. Overall, all of the models produced quite similar results suggesting their may be an upper limit in terms of the accuracy that can be achieved on this problem. \n",
    "\n",
    "Another possible ways to improve the preformace is trying longer sequences, different optimizers and using more LSTM layers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
